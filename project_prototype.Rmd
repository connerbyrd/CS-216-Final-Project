---
title: "CS216 - Final Project"
author: "Steven Yuan (szy2), Conner Byrd (ctb43), Zach Kinne (zpk), Sam Rivera (sfr11)"
date: "December 8, 2022"
output:
  pdf_document:
    fig_cap: yes
  html_document:
    df_print: paged
header-includes:
- \usepackage{float}
- \floatplacement{figure}{H}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, include = FALSE, fig.align = 'center', out.extra = '')
```

```{r libraries, echo = FALSE, show_col_types = FALSE}
library(dplyr)
library(readr)
library(knitr)
library(tidyverse)
library(gridExtra)
library(caret)
library(leaps)
library(MASS)
library(tidyr)
library(ISLR)
library(ROSE)
library(rpart)
library(ggplot2)
library(tidymodels)
library(pROC)
library(corrr)
library(randomForest)
library(janitor)
library(sjPlot)
library(kableExtra)
heart = read_csv("heart_2020_cleaned.csv") %>%
  as_tibble()
```

The full markdown, all code, and data can be accessed at teh following Github repository (https://github.com/connerbyrd/CS-216-Final-Project).

# I. Introduction

According to the Center for Disease Control, heart disease is one of the leading causes of death for people of most races in the United States. About half of all Americans have at least one of three key risk factors for heart disease defined by the CDC (high blood pressure, high cholesterol, and smoking), and detecting and preventing the factors that have the greatest impact on heart disease is very important to healthcare, as heart disease is treatable if there is quick access to equipped hospitals and early diagnosis, as well as key predictive screening to analyze the risk factors of patients. To provide preventative treatment to individuals from having heart disease, it is necessary to be able to determine risk factors which can be used to create actionable prevention plans. Currently, there are several different ways for physicians to diagnose patients that they believe to beat risk for heart disease, which often include measuring blood pressure, cholesterol level, and conducting further tests such as exercise stress tests and electrocardiograms. However, there are many issues with current diagnostic methods. A study of 500 patients found a false positive reading between 77 and 82 percent inpatients in patients at risk of heart disease screened by ECG, and a false negative reading between 6 to 7 percent in the same patient population. To more successfully prevent diagnose individuals that are at risk for heart disease, it is first necessary to be able to determine other strong risk factors which can be used to create actionable prevention plans.

In that aim, our research has two main questions. Our first question is what demographic and health factors tend to be the best at predicting the occurrence of heart disease? To answer this question, we plan on developing predictive models to assess the likelihood of a heart disease diagnostic for potential at-risk patients based on a number of factors. Our second question is what health and demographic factors tend to be associated with higher risk of having heart disease? We plan on creating models for the purpose of interpretation to answer this question and provide a greater understanding of signs that patients can analyze to check their risk for heart disease. Answering these questions requires an in-depth and substantial analysis of patient data. Doing so is relevant to the scientific community given the scope of the disease globally and within the United States. With the current metric of nearly half of Americans at risk of heart disease according to the CDC,diagnosing this issue and proposing a solution has the potential to save the lives and prosperity of millions of lives around the world.

# II. Data Sources

The dataset we utilize to answer our research questions is the 2020 CDC survey as part of the BehavioralRisk Factor Surveillance System, which conducts telephone surveys to gather data on the health status ofUS residents in all 50 states as well as the District of Columbia and three US territories, asking questionsabout the respondentsâ€™ health status and demographic information (please see Works Cited for link to data).The original dataset of nearly 402,000 observations nearly 300 variables was reduced to 18 variables relatingto various demographic health conditions, such as BMI, whether the respondent was a smoker, as well asthe sex and race of the respondent. The categorical variable of whether the respondent has ever had heart disease is also included in the dataset. We acquired the dataset from Kaggle, and the dataset has alreadybeen pre-processed and cleaned by both the CDC and Kaggle, with only observations where all 18 variableshave been recorded kept in the cleaned data (See Appendix A for a description of the variables).

The dataset utilized for our project is relevant and appropriate for addressing our research question as thedataset is one of the largest datasets available on the health status of individuals that includes informationon the prevalence of heart disease. The dataset, collected and curated by the CDC, also has a wide reachacross the United States geographically. The datasets size and geographic breadth will allow us to generalizeour findings across the United States with fewer issues and also has the potential to provide more predictivepower and better data to train our models on than smaller datasets curated elsewhere.

## Data Pre-Processing

The data was already pre-processed by both the CDC and the uploader to Kagle, and had no missing variables. Due to the size of the dataset and the high runtime with fitting models using such a large dataset, we trim down the dataset by sampling 100,000 observations randomly in the dataset, and split the sampled dataset into both a testing and a training set. The 18 variables included include 17 predictor variables as well as the dependent variable, `HeartDisease`. Some of the variables, such as `PhysicalHealth`, `MentalHealth`, and `SleepTime`, make more sense being a proportion of the number of days in the month or number of hours in the day, as `PhysicalHealth` and `MentalHealth` are limited to the number of days in a month and `SleepTime` is limited to 24 hours. Thus, we scale them to be in-between 0 and 1. Furthermore, `BMI` is transformed into a categorical variable defined to conventional medical norms (BMI of under 18.5 is underweight, 18.5 to 25 is considered normal, 25 to 30 is considered overweight, and over 30 is considered obese) as medically, there are very few differences in changes in BMI within a category (ex. a BMI of 21 and 20 are considered both medically to be normal BMIs), and most medical professionals utilize BMI as a categorical variable.

```{r variable mutation, echo = FALSE}
heart = heart %>%
  #select(BMI) %>%
    mutate( BMI = case_when( (BMI < 18.5) ~ "Underweight",
      (BMI < 25)  ~ "Normal",
      (BMI <= 30)  ~ "Overweight",
      (BMI > 30) ~ "Obese"
   )
 )
heart <- heart %>%
  mutate(PhysicalHealth = PhysicalHealth / 30,
         MentalHealth = MentalHealth / 30,
         SleepTime = SleepTime / 30)
heart <- heart %>%
  mutate(HeartDisease = as.factor(HeartDisease)) %>%
  mutate(Smoking = as.factor(Smoking)) %>%
  mutate(AlcoholDrinking = as.factor(AlcoholDrinking)) %>%
  mutate(Stroke = as.factor(Stroke)) %>%
  mutate(DiffWalking = as.factor(DiffWalking)) %>%
  mutate(Sex = as.factor(Sex)) %>%
  mutate(AgeCategory = as.factor(AgeCategory)) %>%
  mutate(Race = as.factor(Race)) %>%
  mutate(Diabetic = as.factor(Diabetic)) %>%
  mutate(PhysicalActivity = as.factor(PhysicalActivity)) %>%
  mutate(GenHealth = as.factor(GenHealth)) %>%
  mutate(Asthma = as.factor(Asthma)) %>%
  mutate(KidneyDisease = as.factor(KidneyDisease)) %>%
  mutate(SkinCancer = as.factor(SkinCancer)) %>%
  mutate(BMI = as.factor(BMI))
```

```{r random sampling of data, echo = FALSE}
set.seed(1234)
heart_sample <- sample_n(heart, 10000)
splits = initial_split(heart_sample, strata = HeartDisease)
train = training(splits) # Training data
test = testing(splits) # Test data
```



```{r, echo = FALSE, include = TRUE, fig.width = 5, fig.height = 2.5}
c4 = c("#0db7c4b0", "#f24745b9")
eda <- ggplot(data = heart, mapping = aes(x = HeartDisease)) +
  geom_bar(fill = c4) +
  labs(y = "Count") +
  ggtitle("Counts of Individuals With and Without Heart Disease \n in Data")
eda
```

As shown above, the data is heavily imbalanced, with far more observations where heart disease was not observed than where it was observed. Imbalanced data poses a problem, as the model being trained would be dominated by the majority class, which in this case is where the patient does not have heart disease. The model would predict the majority class more effectively than the minority class, which is undesirable in this case as we want to ensure a high sensitivity rate as it is far more important to be able to correctly identify individuals with heart disease. A technique to reduce the negative impact of imbalanced datasetes is by subsampling the data. Thus, we upsample the minority class by sampling with replacement so the two classes have the same size to create an upsampled training dataset.

```{r upsampling, echo = FALSE, fig.width = 5, fig.height = 3, fig.cap = "Upsampled Counts of Individuals with and without Heart Disease"}
trainup <- upSample(x = train[, -ncol(train)], y = train$HeartDisease)
c4 = c("#0db7c4b0", "#f24745b9")
eda <- ggplot(data = trainup, mapping = aes(x = HeartDisease)) +
  geom_bar(fill = c4) +
  labs(y = "Count")
```

## Exploratory Data Analysis

We first explore a few potential interesting relationships between the prevalence of heart disease and some general lifestyle and health factors that may be of interest, such as BMI and whether a person smokes or drinks. We first decided to explore any potential relationship between BMI and the prevalence of Heart Disease, as although the usage of BMI is controversial, BMI is still popular in its medical usage in regards to association with heart disease.

```{r echo = FALSE, include = TRUE, fig.height = 2.5}
# Plot between Heart Disease and BMI
plot_bmi = ggplot(heart, aes(x = BMI, fill = HeartDisease)) +
  geom_bar(position = "fill") +
  xlim("Underweight", "Normal", "Overweight", "Obese") +
  labs(x = "Body Mass Index", y = "Proportion", fill = "Heart Disease") +
  ggtitle("Heart Disease vs BMI")
plot_bmi
```

The plot above displays the prevalence of heart disease by BMI classification. From the visual analysis, it appears that higher body mass may be correlated with a higher chance of heart disease than normal BMI. Underweight BMI may also be correlated with a higher chance of heart disease. This seems to reinforce the generally accepted medical concept that a normal BMI is most conducive to better general health.

```{r echo = FALSE, include = TRUE, fig.height = 2.5}
# Plot between Heart Disease and Smoking
plot_smoking = ggplot(heart, aes(x = Smoking, fill = HeartDisease)) +
  geom_bar(position = "fill") +
  labs(x = "Smoking", y = "Proportion", fill = "Heart Disease") +
  ggtitle("Heart Disease vs Smoking")


# Plot between Heart Disease and AlcoholDrinking
plot_Alcohol_Drinking = ggplot(heart, aes(x = AlcoholDrinking, fill = HeartDisease)) +
  geom_bar(position = "fill") +
  labs(x = "Alcohol Drinking", y = "Proportion", fill = "Heart Disease") +
  ggtitle("Heart Disease vs Alcohol Drinking")
grid.arrange(plot_smoking, plot_Alcohol_Drinking, ncol = 2) 
```

The plots above display the prevalence of heart disease by whether or not the respondent is a smoker (defined as having smoked at least 100 cigarettes) and whether or not the respondent is a heavy drinker. From the plots, it appears that smokers may be positively associated with a higher chance of heart disease. Interestingly, it appears that heavy drinking may be associated with a lower chance of heart disease.

# III. Modules Used

Being that our project will involve locating relevant predictors and using them to make inferences, Modules 3, 5, and 9 are all very applicable. 

### Module 3 - Probability

Probability is a foundational aspect of statistics and is used heavily when running experiments, making predictions or estimations, using distributions, and much more. Throughout the course of our project, we expect to use probability for numerous applications. The vast majority of these applications will come during the data investigation, data analysis, and final report portions of the project. When looking for significant predictors, probability is used in the form of p-values and is compared against a set alpha level in order to determine statistical significance. We will use probability in this manner to determine which patient variables lead to an increased risk of heart disease. Probability is also an important aspect of statistical distributions, which we expect to use substantially throughout our project. Noting which distributions to use based on the relationships between the response (heart disease indicator) and the various dependent variables will determine useful probabilities that can then be analyzed. Other probabilistic values such as the mean, variance, and standard deviation will also be useful for prediction, estimation, and even data imputation for certain patient lifestyle variables.

### Module 5 - Statistical Inference

Much like probability, statistical inference is highly important for making conclusions about data. In our project, the majority of statistical inference will come in the form of hypothesis testing. Using hypothesis testing, we will be able to test certain variables for their significance when it comes to heart disease occurrence. From there, we can use the techniques described in Module 3 to determine exactly which health and body attributes most prominently lead to an increased risk in heart disease. Much like with probability, we expect to use statistical inference in the data investigation, analysis, and final report sections of the project.

### Module 9 - Prediction & Supervised Machine Learning

Seeing as one of our research questions revolves entirely around prediction, we will be using concepts from Module 9 liberally throughout our project. Linear and Logistic Regression will be very useful to help us construct models of both numerical and categorical data and aid us in our predictive efforts. Other concepts learned in Module 9 will be helpful with checking for correlation between variables, performing stepwise regression, constructing a decision tree or support vector machine, and more. These techniques will allow us to further our understanding of the relationship between predictors and heart disease occurrence and to construct accurate models that we can then make sensible interpretations from. We will also likely end up splitting the data into training and testing cohorts in order to perform further analysis of variable selection and model fit. Prediction will be used in the data analysis and final report portions of the project.


# IV. Preliminary Results and Methods

See 'Discussion of Results' below for a higher-level discussion of important findings
A higher-level discussion of important and notable findings are included in the "Discussion of Results" section below. See Appendices B and C for the full model outputs of the model for inference and for prediction, respectively.

## Model for Inference

We decided to utilize a logistic regression model, with whether the person has heart disease (`HeartDisease`) as the response variable, to examine the relationship between the log-odds of heart disease and various predictors. The general logistic regression model form is formulated by the equation:
$$\log(\frac{P_i}{1-P_i}) = \beta_0+\beta_1X_{1,i}+\beta_2X_{2,i}+...+\beta_kX_{k,i}$$
Using logistic regression lends itself well to both inference and prediction. For the purposes of inference, we decided to fit a model including all variables, as we are interesting in exploring the relationship between the predictors and the response variable. We do not utilize any automated variable selection method for our inference exploration, as variable selection methods such as stepwise selection may drop variables based on its criteria that we are still interested in examining the relationship with the response variable. We utilize the training split from the 100,000-large sample as the data to train the model on, as mentioned in section II.

\renewcommand{\arraystretch}{.8}

```{r full model, echo = FALSE, include = TRUE}
heart_full <- glm(HeartDisease ~ ., family = "binomial", data = train)
output_glm_inference <- clean_names(as.data.frame(summary(heart_full)$coefficients)) %>%
  mutate(pr_z = if_else(pr_z < 0.01, 0.00, pr_z),
         pr_z = ceiling(pr_z*10000)/10000,
         pr_z = as.character(pr_z),
         pr_z = if_else(pr_z == "0", "<0.001", pr_z)) %>%
  kable(digits = 4) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

## Model for Prediction

Whereas we utilize the full model for inference, we are interested in model performance for prediction. To select for models, we utilize stepwise selection, which consists of iteratively adding and removing predictors, in the predictive model, to find the subset of variables resulting in the best performing model with the lowest prediction error. To select for variables, we began by performing both forwards and backwards selection on the full model. These forms of stepwise regression allow us to select for variables that result in the model lowest possible AIC value. AIC itself is an estimator of the predictive error of a model, allowing us to directly assess our model's performance.

Performing forwards and backwards selection resulted in the dropping of 6 variables from our model: $BMI$, $PhysicalHealth$, $MentalHealth$, $Race$, $PhysicalActivity$, and $SkinCancer$.

\renewcommand{\arraystretch}{.8}

```{r stepwise, echo = FALSE, include = TRUE}
#splits1 = initial_split(heart_sample, strata = HeartDisease)
#train1 = training(splits) # Training data
#test1 = testing(splits) # Test data
#takes ~25 secs to run
step_model <- stepAIC(heart_full, direction = "both", trace = FALSE)
model_prediction <- clean_names(as.data.frame(summary(step_model)$coefficients)) %>%
  mutate(pr_z = if_else(pr_z < 0.01, 0.00, pr_z),
         pr_z = ceiling(pr_z*10000)/10000,
         pr_z = as.character(pr_z),
         pr_z = if_else(pr_z == "0", "<0.001", pr_z)) %>%
  kable(digits = 4) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

## Discussion of Results

### Full Model for Inference

Being that we used a logistic regression model to perform inference, we can interpret the coefficients in our results as the expected increase in log-odds of having heart disease for each predictor. At the alpha = 0.05 level, we note 10 predictor variables that appear to be statistically significant for predicting heart disease. The odds that an individual who has smoked at least 100 cigarettes in their lifetime ($SmokingYes$) will develop heart disease is expected to be $e^{0.1901}$ = 1.2094 times greater than an individual who hasn't. The odds that a male who drinks at least 14 alcoholic drinks per week or female who drinks at least 7 alcoholic drinks per week ($AlcoholDrinkingYes$) will develop heart disease is expected to be $e^{0.5441}$ = 1.7231 times greater than an individual who doesn't. The odds than an individual who has had a stroke in their lifetime ($StrokeYes$) will develop heart disease is expected to be $e^{1.0265}$ = 2.7913 times greater than an individual who hasn't. The odds that an individual who has difficulty walking or climbing stairs ($DiffWalkingYes$) will develop heart disease is expected to be $e^{0.3737}$ = 1.4531 times greater than an individual who doesn't. The odds that an individual who is male ($SexMale$) will develop heart disease is expected to be $e^{0.7575}$ = 2.1329 times greater than an individual who is female. Six different age categories appeared to be significant predictors of heart disease in our model: 55 to 59, 60 to 64, 65 to 69, 70 to 74, 75 to 79, and 80+. Of these, the 80+ age category had the greatest coefficient of 2.3623. The odds that an individual who is 80 years old or older ($AgeCategory80 or older$) will develop heart disease is $e^{2.3623}$ = 10.6153 times greater than someone who is 24 years old or younger (the baseline category). The odds that an individual who is diabetic ($DiabetesYes$) will develop heart disease is expected to be $e^{.4200}$ = 1.5220 times greater than an individual who isn't. All categories of general health appeared to be significant predictors of heart disease in our model. Of these, the poor general health category had the greatest coefficient of 1.6418. The odds that an individual with poor general health ($GenHealthPoor$) will develop heart disease is expected to be $e^{1.6418}$ = 5.1645 times greater than those who aren't. The odds that an individual who has asthma ($AsthmaYes$) will develop heart disease is expected to be $e^{0.2555}$ = 1.2911 times greater than an individual who doesn't. The odds that an individual who has kidney disease ($KidneyDiseaseYes$) will develop heart disease is expected to be $e^{0.7999}$ = 2.2253 times greater than an individual who doesn't. 

### Predictive Model

To observe our model's initial predictive performance, we performed k-fold cross validation. K-fold cross validation starts by splitting the dataset into k equally sized "folds". Then, for each unique group, 1 fold is held out as the test dataset whereas the other remaining folds combine to form the training dataset. We found that for values 1 < k < 21, k = 5 (5-fold cross validation) produced the highest model accuracy, at 91.28% (see Appendix D for full output).

```{r k-fold-cv, echo = FALSE, include = TRUE}
set.seed(1234)
train_control <- trainControl(method = "cv", number = 5)
modelpred <- train(HeartDisease ~ Smoking + AlcoholDrinking + Stroke + DiffWalking + Sex + AgeCategory + Diabetic + GenHealth + SleepTime + Asthma + KidneyDisease, data = heart_sample, method = "glm", 
               trControl = train_control)
print(modelpred)
```

For further interpretation and analysis of our model, we fit a random forest. A random forest combines multiple decision trees (in this case, 20) in order to yield the most common prediction class for certain values of the predictor variables. The out-of-bag error from this model (the black line) is 0.1%, meaning we expect this model to classify patients incorrectly around 0.1% of the time. We can also observe the false positive rate (green) and false negative rate (red) that comprise this out-of-bag error.

```{r decision-trees, echo = FALSE}
x <- model.matrix(HeartDisease~., trainup)[,-1]
y <- trainup$HeartDisease
```

```{r echo = FALSE, include = TRUE, fig.height = 4, fig.width = 6, fig.cap = "Error Lines for Random Forest"}
set.seed(1)
rf.heart <- randomForest(HeartDisease ~ ., data = trainup, mtry = sqrt(11), ntree = 20)
plot(rf.heart)
legend("top", colnames(rf.heart$err.rate),col=1:6,cex=0.8,fill=1:6)
confusion <- round(rf.heart$confusion, 4) %>% as.character()
flag.1 <- c("Out-of-bag Error", "", "Actually 0", "Actually 1")
flag.2 <- c("0.1%", "Predicted as 0", confusion[1], confusion[2])
flag.3 <- c("","Predicted as 1", confusion[3], confusion[4])
flag.4 <- c("", "Class Error", confusion[5], confusion[6])
tibble(flag.1, flag.2, flag.3, flag.4) %>% 
  kable(col.names = rep(" ", 4),
        caption = "Output of the optimal Random Forest model in the first MICE Chain") %>% 
  row_spec(1, bold = T) %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  pack_rows(index = c(" " = 1, "Confusion Matrix" = 3))
```


# V. Limitations and Future Work

### Limitations

Model Specification: Steven can u talk about this thanks

Generalizability: While the dataset we used is relatively broad in its scope and application, some of its aspects could have an impact on its generalizability. The data in the dataset comes from the Behavioral Risk Factor Surveillance System (BRFSS). Run by the CDC, this system collects health status data from individuals via telephone call. While this is likely the simplest way for this form of data collection, it does introduce a voluntary response bias that could affect the composition of the data. For example, someone with health issues could be more keen to sharing their health status data as opposed to a healthy individual who may believe the survey has no importance for them. Additionally, some individuals may not respond to the phone call altogether. These biases could skew the results of our methodology in a way we are not able to account for. In addition, the survey was conducted only on individuals within the United States. While the USA is a demographically diverse nation, its population only accounts for 4.25% of the Earth's total population. It is very well possible that in other countries, certain predictors that were deemed statistically insignificant here could have very little effect on the prediction of heart disease and vice versa. As a result, the conclusions we obtained are only generalizable to adults residing in the 50 US states, Washington DC, and three US territories.

Missingness: The original dataset collected by the CDC consisted of over 400,000 observations of 300 different health and demographic variables. This was then reduced to the 18 variables in the dataset we used by its curator on Kaggle. Although this was done "to select the most relevant variables" and "be usable for machine learning projects", no in depth statistical detail was given for the removal of these variables. Therefore, we are unable to determine their possible influence on our results. It is possible that some of these variables could have been statistically significant predictors of heart disease in our inferential model or aided in the model accuracy for our predictive model.

### Next Steps


# VII. Appendix

## Appendix A: Full Description of Variables 

`HeartDisease`: An indicator variable that equals 1 if respondents indicate they have had coronary heart disease (CHD) or myocardial infarction (MI).

`BMI`: Body Mass Index (BMI)

`Smoking`: Indicator variable that indicates if the respondent has smoked at least 100 cigarettes, equal to 5 packs, in their life

`AlcoholDrinking`: Indicator variable that indicates if the respondent identifies as a heavy drinker (defined as having more than 14 drinks per week for adult men and more than 7 drinks per week for adult women).

`Stroke`: Indicator variable that indicates whether or not the respondent has had a stroke.

`PhysicalHealth`: The number of days over the past 30 days the respondent has had physical illness or industry.

`MentalHealth`: The number of days over the past 30 days the respondent has had poor mental health.

`DiffWalking`: Indicator variable that indicates if the respondent has had serious difficulty walking or climbing stairs.

`Sex`: Indicator variable that indicates the sex of the respondent as male or female.

`AgeCategory`: The age of the respondent, split into 14 levels.

`Race`: The imputed race/ethnicity of the respondent

`Diabetic`: Whether or not the respondent has had diabetes.

`PhysicalActivity`: Indicator variable indicating whether or not the respondent has done physical activity or exercise during the past 30 days other than their regular job.

`GenHealth`: The respondent's self-identification of their general health, split into five different levels, from "poor" to "excellent".

`SleepTime`: The average amount of sleep the respondent gets in a 24-hour period.

`Asthma`: Indicator variable indicating whether or not the respondent has had asthma.

`KidneyDisease`: Indicator variable indicating whether or not the respondent has had kidney disease, not including bladder infection or kidney stones.

`SkinCancer`: Indicator variable indicating whether or not the respondent has had skin cancer.

## Appendix B: Full Model Output for Inferential Logistic Regression Model

```{r full model output, echo = FALSE, include = TRUE}
output_glm_inference
```

## Appendix C: Full Model Output for Prediction Logistic Regression Model

```{r stepwise model output, echo = FALSE, include = TRUE}
model_prediction
```

## Appendix D: Predictive Model K-Fold Validation Output

```{r k-fold-cv output, echo = FALSE, include = TRUE}
print(modelpred)
```

# Citations

Kaggle. (n.d.). Personal Key Indicators of Heart Disease. Kaggle. Retrieved October 15, 2022, from
https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease
